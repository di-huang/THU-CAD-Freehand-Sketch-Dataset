<!DOCTYPE html>
<html lang="en">
<head>
    <title></title>
    <meta charset="utf-8" />
    <link rel="icon" href="favicon.png" type="image/x-icon" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
    <link href="css/vendor/bootstrap.css" rel="stylesheet" />
    <link href="css/vendor/font-awesome.css" rel="stylesheet" />
    <link href="css/vendor/slick.css" rel="stylesheet" />
    <link href="css/vendor/slick-theme.css" rel="stylesheet" />
    <link href="css/vendor/odometer-theme-default.css" rel="stylesheet" />
    <link href="css/main.css" rel="stylesheet" />
    <style>
        .logo {
            margin-left: -120px; /* 调整这个数值以控制logo左移的距离 */
            margin-top: 25px;
        }
    </style>
</head>
<body>

    <header>
        <div class="container">
            <div class="logo">
                <a href="index.html"><img src="assets/img/thu2.png" alt="" width="100" height="100"/></a>
            </div>
            <div class="menu">
                <ul>

                </ul>
            </div>
            <div class="mobile-menu"><i class="fa fa-bars"></i></div>
        </div>
    </header>

    <div class="home-slider">
        <div class="home-slider--wrapper">
            <div>
                <div class="home-slider--wrapper__inner" style="background-image: url('assets/img/Tsinghua_dataset.png')">
                    <div class="container">
                        <!-- <div style="height: 60px;"></div> -->
                        <h2>A Large-Scale Multi-Modal Dataset for Sketch-based Engineering Product Modeling</h2>
                        <!-- <h1>THU CAD Freehand Sketch Dataset</h1> -->
                        <span class="dot-dash">.</span>
                        <h3>Anonymous authors</h3>
                        <h3>Tsinghua university</h3>
                        <p>The integration of Artificial Intelligence (AI) and Engineering Product Modeling (EPM) becomes increasingly promising. Freehand sketches and corresponding CAD models are important modalities in data-driven algorithms of sketch-based EPM applications. However, datasets with these paired modalities are rare, and most existing sketch datasets for CAD models either lack a freehand style or are insufficient. Thus, we propose a large-scale multi-modal dataset of paired freehand sketches and CAD models, the SketchEPM dataset. Our dataset covers 23 categories, 9759 CAD models in B-Rep format, 33300 real freehand sketches, and 35873 synthetic sketches. SketchEPM can be easily expanded using our data creation pipeline. We conduct key tasks on our dataset, including sketch recognition, sketch-to-CAD model retrieval, and sketch-based 3D model reconstruction. The experimental results point out the limitations of current models for these tasks. We release the dateset for facilitating the development of sketch-based EPM research and applications.</p>
                        <div class="slider-buttons">
                            <!-- <a href="assets/THUD_Robotic_Dataset_TOS.pdf" class="button">Dataset Application Form</a> -->
                            <a href="https://pan.baidu.com/s/1CIl172BQaEbJ6DJHpOGs1A?pwd=0324" class="button" id="myButton">Dataset</a>
<!--                             <a href="https://www.overleaf.com/read/vhvqnwfbmmbc#d9ec4b" class="button button-w">PAPER</a> -->
                            <!-- <a href="https://github.com/jackyzengl/THUD_Dataset_Overview" class="button button-w">Github</a> -->
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="home-slider--anchor">
            <span><i class="fa fa-anchor" aria-hidden="true"></i></span>
        </div>
    </div>

    <div class="wrapper">
        <!-- <section class="four-elements">
            <div class="container">
                <div class="row">
                    <div class="col-md-3 col-sm-6 col-xs-12">
                        <div class="four-elements--image"><i class="fa fa-lightbulb-o" aria-hidden="true"></i></div>
                        <h3>large scale & dynamic</h3>
                        <p>Our dataset provides dynamic annotated data for large scale indoor scene which contains amount of dynamic objects that present significant challenges for robot tasks.</p>
                    </div>
                    <div class="col-md-3 col-sm-6 col-xs-12">
                        <div class="four-elements--image"><i class="fa fa-lightbulb-o" aria-hidden="true"></i></div>
                        <h3>scene understanding</h3>
                        <p>Our dataset supports training and testing for various robotic scene understanding tasks (object detection, semantic segmentation, robot relocalization, scene reconstruction, etc.)</p>
                    </div>
                    <div class="col-md-3 col-sm-6 col-xs-12">
                        <div class="four-elements--image"><i class="fa fa-lightbulb-o" aria-hidden="true"></i></div>
                        <h3>selective focus</h3>
                        <p> Our dataset contains both real and synthetic annotated data, the expansion of its size and capabilities has great potential in the future.</p>
                    </div>
                    <div class="col-md-3 col-sm-6 col-xs-12">
                        <div class="four-elements--image"><i class="fa fa-lightbulb-o" aria-hidden="true"></i></div>
                        <h3>Rich labels</h3>
                        <p>Multiple labels such as instance segmentation, semantic segmentation, 3D/2D object detection, Depth, RGB, pose, etc., widely applicable in various fields.</p>
                    </div>
                </div>
            </div>
        </section> -->

        <!-- <section class="our-history">
            <div class="video-container">
                <div class="video-wrapper">
                    <h1 class="video-title">Display Video:</h1>
                    <video controls width="100%" height="auto" class="rounded-video">
                        <source src="assets/moive/dataset_v4.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </section> -->

        <section class="statistics">
            <div class="container">
            </div>
        </section>


        <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">SketchEPM Dataset:</h1>
              <img src="assets/img/framework.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">Real sketch data acquisition software:</h1>
              <img src="assets/img/fig_data_collection_tool.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">Category distribution of the dataset:</h1>
              <img src="assets/img/shujujistat.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section-long">
            <div class="image-wrapper">
            <h1 class="pic-title-2">Analysis of the user's hand-drawing process:</h1>
              <img src="assets/img/yonghushouhuifenxi.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section-long">
            <div class="image-wrapper">
            <h1 class="pic-title-2">User diversity statistics:</h1>
              <img src="assets/img/yonghuduoyang.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

<!--         <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">Classification experiment:</h1>
              <img src="assets/img/fenlei.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">Retrieval experiment:</h1>
              <img src="assets/img/jiansuo.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section> -->



        <!-- <section class="partners">
            <div class="container">
                <h2>Cooperative unit</h2>
                <p>Thank you to the following units for their support and assistance.</p>
                <span class="dot-dash dark">.</span>
                <div class="partners--container">
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/thu3.png" alt="">
                        </div>
                    </div>
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/shuju&xinxi.png" alt="">
                        </div>
                    </div>
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/immv_sigle.png" alt="">
                        </div>
                    </div>
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/pudu.png" alt="">
                        </div>
                    </div>
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/pudu_tech.png" alt="">
                        </div>
                    </div>
                </div>
            </div>
        </section> -->

        <!-- <section class="get-started">
            <div class="container">
                <h2>If you use the ScanNet data or code please cite:</h2>
                <p>@inproceedings{2024ICRA,<br>
                    title={Mobile Oriented Large-Scale Indoor Dataset for Dynamic Scene Understanding},<br>
                    author={Yi-Fan Tang, Cong Tai, Fang-Xin Chen, Wan-Ting Zhang, Tao Zhang, Yong-Jin Liu, Long Zeng*},<br>
                    booktitle = {Mobile Oriented Large-Scale Indoor Dataset for Dynamic Scene Understanding, submitted to IEEE International Conference Robotic and Automation, 2024.}},<br>
                </p>
                <a href="#" class="button">full papers</a>
            </div>
        </section> -->
    </div>

    <!-- <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-sm-12">
                </div>
                <div class="col-md-6 col-sm-12">
                    <p><a target="#" href="#" title="Last updated: 2024.5.1">Last updated: 2024.5.1</a></p>
                    <p>Number of downloads:<span id="clickCount">1</span></p>
                </div>
            </div>
        </div>
    </footer> -->

    <script type="text/javascript">
        window.odometerOptions = {
            format: '(,ddd)',
        };
    </script>
    <script src="js/vendor/jquery-3.1.0.min.js"></script>
    <script src="js/vendor/jquery.easing.min.js"></script>
    <script src="js/vendor/tether.js"></script>
    <script src="js/vendor/bootstrap.js"></script>
    <script src="js/vendor/slick.js"></script>
    <script src="js/vendor/isotope.pkgd.min.js"></script>
    <script src="js/vendor/odometer.min.js"></script>
    <script src="js/main.js"></script>
</body>
</html>
